{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Camera calibration\n",
    "\n",
    "def calculate_camera_matrix_and_disturtion_coefficients(nx,ny,path):\n",
    "\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    images = glob.glob(path)\n",
    "\n",
    "    \n",
    "    objp = np.zeros((ny*nx,3),np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "    image_shape = None;\n",
    "\n",
    "    for image in images:\n",
    "        # Convert to grayscale\n",
    "        img = cv2.imread(image)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        if image_shape == None:\n",
    "            image_shape = gray.shape[::-1]\n",
    "            \n",
    "        # Find the chessboard corners\n",
    "        ret,corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "       \n",
    "    \n",
    "        # If found, draw corners\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints,image_shape , None, None)\n",
    "    return mtx, dist\n",
    "    \n",
    "    \n",
    "path = '/Users/test/Desktop/SDCND/CarND-Advanced-Lane-Lines/camera_cal/calibration*.jpg'   \n",
    "mtx, dist = calculate_camera_matrix_and_disturtion_coefficients(9,6,path)\n",
    "img = cv2.imread('/Users/test/Desktop/SDCND/CarND-Advanced-Lane-Lines/camera_cal/calibration1.jpg')\n",
    "undistorted = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.) \n",
    "f.savefig('./writeup_images/undistort_output.png')\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "img = cv2.imread('/Users/test/Desktop/SDCND/CarND-Advanced-Lane-Lines/test_images/test6.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "undistorted = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.) \n",
    "f.savefig('./writeup_images/test6.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test images\n",
    "test_imagenames = glob.glob('/Users/test/Desktop/SDCND/CarND-Advanced-Lane-Lines/test_images/test*.jpg') \\\n",
    "+ glob.glob('/Users/test/Desktop/SDCND/CarND-Advanced-Lane-Lines/test_images/straight_lines*.jpg')\n",
    "\n",
    "test_images = []\n",
    "test_images_gray = []\n",
    "\n",
    "for name in test_imagenames:\n",
    "   test_images.append(cv2.undistort(mpimg.imread(name), mtx, dist, None, mtx))\n",
    "\n",
    "for image in test_images:\n",
    "   test_images_gray.append(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY))\n",
    "   \n",
    "image_length = len(test_images) \n",
    "\n",
    "def show_plots(images,type):\n",
    "    image_length = int(len(images)/2) \n",
    "    f, ax = plt.subplots(1, image_length, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    for i in range(0,image_length):\n",
    "        if(type == \"gray\"):\n",
    "            ax[i].imshow(images[i],cmap = \"gray\")\n",
    "        else:\n",
    "            ax[i].imshow(images[i])\n",
    "        #ax[i].set_title( imagenames[i] , fontsize=5)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    f, ax = plt.subplots(1, image_length, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    for i in range(image_length,image_length*2):\n",
    "        if(type == \"gray\"):\n",
    "            ax[i-image_length].imshow(images[i],cmap = \"gray\")\n",
    "        else:\n",
    "            ax[i-image_length].imshow(images[i])\n",
    "        #ax[i-image_length].set_title( imagenames[i] , fontsize=5)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "   \n",
    " \n",
    "\n",
    "show_plots(test_images,None)\n",
    "show_plots(test_images_gray,\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Color spaces, gradients exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold_min = 10\n",
    "threshold_max = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getSobel(images,orient,threshold):\n",
    "    sobel = None\n",
    "    sobel_images = []\n",
    "    for image in images:\n",
    "       if(orient == 'y'):\n",
    "           sobel = cv2.Sobel(image, cv2.CV_64F, 0, 1)\n",
    "       else:\n",
    "           sobel = cv2.Sobel(image, cv2.CV_64F, 1, 0)\n",
    "       abs_sobel = np.absolute(sobel)\n",
    "       scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "       sbinary = np.zeros_like(scaled_sobel)\n",
    "       sbinary[(scaled_sobel >= threshold[0]) & (scaled_sobel <= threshold[1])] = 1\n",
    "       sobel_images.append(sbinary)\n",
    "    return sobel_images \n",
    "    \n",
    "sobelx_images = getSobel(test_images_gray,'x',(threshold_min,threshold_max))\n",
    "sobely_images = getSobel(test_images_gray,'y',(threshold_min,threshold_max))\n",
    "\n",
    "show_plots(sobelx_images,\"gray\")\n",
    "show_plots(sobely_images,\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_thresh(gray_images, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    images = []\n",
    "    for i in range(0,len(gray_images)):\n",
    "        sobelx = cv2.Sobel(gray_images[i], cv2.CV_64F, 1, 0,ksize=sobel_kernel)\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "    \n",
    "        sobely = cv2.Sobel(gray_images[i], cv2.CV_64F, 0, 1,ksize=sobel_kernel)\n",
    "        abs_sobely = np.absolute(sobely)\n",
    "       \n",
    "        \n",
    "        abs_sobelxy = np.sqrt(np.power(sobelx,2) + np.power(sobely,2))\n",
    "        np.uint8(255*abs_sobelx/np.max(abs_sobelxy))\n",
    "        scaled_sobel = np.uint8(255*abs_sobelxy/np.max(abs_sobelxy))\n",
    "        binary_output = np.zeros_like(scaled_sobel)\n",
    "        binary_output[(scaled_sobel>=mag_thresh[0]) & (scaled_sobel<=mag_thresh[1]) ] = 1\n",
    "        images.append(binary_output)  \n",
    "    return images  \n",
    "    \n",
    "\n",
    "mag_binary = mag_thresh(test_images_gray, sobel_kernel=3, mag_thresh=(threshold_min,threshold_max))\n",
    "show_plots(mag_binary,\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_threshold(gray_images, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    images = []\n",
    "    for i in range(0,len(gray_images)):\n",
    "        sobelx = cv2.Sobel(gray_images[i], cv2.CV_64F, 1, 0,ksize=sobel_kernel)\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "    \n",
    "        sobely = cv2.Sobel(gray_images[i], cv2.CV_64F, 0, 1,ksize=sobel_kernel)\n",
    "        abs_sobely = np.absolute(sobely)\n",
    "       \n",
    "        \n",
    "        abs_sobelxy = np.arctan2(abs_sobely, abs_sobelx)\n",
    "\n",
    "        binary_output = np.zeros_like(abs_sobelxy)\n",
    "        binary_output[(abs_sobelxy>=thresh[0]) & (abs_sobelxy<=thresh[1]) ] = 1\n",
    "        images.append(binary_output)  \n",
    "    return images\n",
    "    \n",
    "    \n",
    "dir_binary = dir_threshold(test_images_gray, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "show_plots(dir_binary,\"gray\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_combined(sobelx,dir_binary):\n",
    "    images = []\n",
    "    for i in range(0,len(sobelx)):\n",
    "        image = np.zeros_like(sobelx[0])\n",
    "        image[(sobelx[i] == 1) | (dir_binary == 1)] = 1\n",
    "        images.append(image)\n",
    "    return images    \n",
    "    \n",
    "combined = get_combined(sobelx_images,dir_binary)\n",
    "show_plots(combined,\"gray\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s_channel(test_images):\n",
    "    images = []\n",
    "    for image in test_images:\n",
    "       hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "       s = hls[:,:,2]\n",
    "       images.append(s)\n",
    "    return images  \n",
    "    \n",
    "s_channel_images = get_s_channel(test_images)  \n",
    "    \n",
    "show_plots(s_channel_images,\"gray\")\n",
    "\n",
    "s_channel_sobelx_images = getSobel(s_channel_images,'x',(threshold_min,threshold_max))\n",
    "s_channel_sobely_images = getSobel(s_channel_images,'y',(threshold_min,threshold_max))\n",
    "\n",
    "show_plots(s_channel_sobelx_images,\"gray\")\n",
    "show_plots(s_channel_sobely_images,\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_channel_mag_binary = mag_thresh(s_channel_images, sobel_kernel=3, mag_thresh=(threshold_min,threshold_max))\n",
    "show_plots(s_channel_mag_binary,\"gray\")\n",
    "\n",
    "s_channel_dir_binary = dir_threshold(s_channel_images, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "show_plots(s_channel_dir_binary,\"gray\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_channel_combined = get_combined(s_channel_sobelx_images,s_channel_dir_binary)\n",
    "show_plots(s_channel_combined,\"gray\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r_channel(test_images):\n",
    "    images = []\n",
    "    for image in test_images:\n",
    "       r = image[:,:,0]\n",
    "       images.append(r)\n",
    "    return images  \n",
    "    \n",
    "r_channel_images = get_r_channel(test_images)  \n",
    "    \n",
    "show_plots(r_channel_images,\"gray\")\n",
    "\n",
    "r_channel_sobelx_images = getSobel(r_channel_images,'x',(threshold_min,threshold_max))\n",
    "r_channel_sobely_images = getSobel(r_channel_images,'y',(threshold_min,threshold_max))\n",
    "\n",
    "show_plots(r_channel_sobelx_images,\"gray\")\n",
    "show_plots(r_channel_sobely_images,\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_channel_mag_binary = mag_thresh(r_channel_images, sobel_kernel=3, mag_thresh=(threshold_min,threshold_max))\n",
    "show_plots(r_channel_mag_binary,\"gray\")\n",
    "\n",
    "r_channel_dir_binary = dir_threshold(r_channel_images, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "show_plots(r_channel_dir_binary,\"gray\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_channel_combined = get_combined(r_channel_sobelx_images,r_channel_dir_binary)\n",
    "show_plots(r_channel_combined,\"gray\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l_channel(test_images):\n",
    "    images = []\n",
    "    for image in test_images:\n",
    "       hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "       l = hls[:,:,1]\n",
    "       images.append(l)\n",
    "    return images  \n",
    "    \n",
    "l_channel_images = get_l_channel(test_images)  \n",
    "    \n",
    "show_plots(l_channel_images,\"gray\")\n",
    "\n",
    "l_channel_sobelx_images = getSobel(l_channel_images,'x',(threshold_min,threshold_max))\n",
    "l_channel_sobely_images = getSobel(l_channel_images,'y',(threshold_min,threshold_max))\n",
    "\n",
    "show_plots(l_channel_sobelx_images,\"gray\")\n",
    "show_plots(l_channel_sobely_images,\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_channel_mag_binary = mag_thresh(l_channel_images, sobel_kernel=3, mag_thresh=(threshold_min,threshold_max))\n",
    "show_plots(l_channel_mag_binary,\"gray\")\n",
    "\n",
    "l_channel_dir_binary = dir_threshold(l_channel_images, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "show_plots(l_channel_dir_binary,\"gray\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_channel_combined = get_combined(l_channel_sobelx_images,l_channel_dir_binary)\n",
    "show_plots(l_channel_combined,\"gray\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_channels_combined(s_channel_combined,l_channel_combined):\n",
    "    images = []\n",
    "    for i in range(0,len(s_channel_combined)):\n",
    "        image = np.zeros_like(combined[0])\n",
    "        temp = np.add(s_channel_combined[i],l_channel_combined[i])\n",
    "        image[temp>0] = 1\n",
    "        images.append(image)\n",
    "    return images  \n",
    "\n",
    "all_channel_combined = get_all_channels_combined(s_channel_combined,l_channel_combined)\n",
    "show_plots(all_channel_combined,\"gray\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_region_interest(combined_channel_images):\n",
    "    images = []\n",
    "    for image in combined_channel_images:\n",
    "        height, width = image.shape[0], image.shape[1]\n",
    "        bl = (width / 2 - 480, height - 30)\n",
    "        br = (width / 2 + 480, height - 30)\n",
    "        tl = (width / 2 - 60, height / 2 + 76)\n",
    "        tr = (width / 2 + 60, height / 2 + 76)\n",
    "\n",
    "        fit_left = np.polyfit((bl[0], tl[0]), (bl[1], tl[1]), 1)\n",
    "        fit_right = np.polyfit((br[0], tr[0]), (br[1], tr[1]), 1)\n",
    "        fit_bottom = np.polyfit((bl[0], br[0]), (bl[1], br[1]), 1)\n",
    "        fit_top = np.polyfit((tl[0], tr[0]), (tl[1], tr[1]), 1)\n",
    "\n",
    "        # Find the region inside the lines\n",
    "        xs, ys = np.meshgrid(np.arange(0, image.shape[1]), np.arange(0, image.shape[0]))\n",
    "        mask = (ys > (xs * fit_left[0] + fit_left[1])) & \\\n",
    "               (ys > (xs * fit_right[0] + fit_right[1])) & \\\n",
    "               (ys > (xs * fit_top[0] + fit_top[1])) & \\\n",
    "               (ys < (xs * fit_bottom[0] + fit_bottom[1]))\n",
    "    \n",
    "        img_window = np.copy(image)\n",
    "        img_window[mask == False] = 0\n",
    "        images.append(img_window)\n",
    "    return images\n",
    "    \n",
    "ROI_all_channel_combined = isolate_region_interest(all_channel_combined)\n",
    "show_plots(ROI_all_channel_combined,\"gray\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#determine src points\n",
    "test_image_index = 5\n",
    "offset =0\n",
    "img_size = (img.shape[1],img.shape[0])\n",
    "\n",
    "src = np.float32([[545,473],[800,473],[1259,683],[23,683]])\n",
    "\n",
    "#determine src points\n",
    "dst = np.float32([[offset,0], [img_size[0]-offset, 0], \n",
    "                                     [img_size[0]-offset, img_size[1]-offset], \n",
    "                                     [offset, img_size[1]-offset]])\n",
    "\n",
    "src = np.float32([(257, 685), (1100, 685), (583, 460),(720, 460)])\n",
    "dst = np.float32([(200, 720), (1080, 720), (200, 0), (1080, 0)])\n",
    "\n",
    "def warp_image(img):\n",
    "    \n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped\n",
    "\n",
    "\n",
    "warped = warp_image(ROI_all_channel_combined[test_image_index])\n",
    "Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "img_copy = np.copy(img)\n",
    "pts = np.array([(257, 685),(583, 460),(720, 460), (1100, 685) ], np.int32)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "cv2.polylines(img_copy,[pts],True,(0,255,0),2)\n",
    " \n",
    "img_copy_warped = warp_image(img_copy)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img_copy)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(img_copy_warped)\n",
    "ax2.set_title('warped Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.) \n",
    "f.savefig('./writeup_images/warp_confirmation.jpg')\n",
    "\n",
    "\n",
    "\n",
    "# plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.) \n",
    "\n",
    "                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(warped,cmap=\"gray\")\n",
    "plt.title('Warped binary Image\\n')\n",
    "plt.savefig('./writeup_images/warped_straight_lines.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding window search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = np.sum(warped [warped .shape[0]//2:,:], axis=0)\n",
    "plt.plot(histogram)\n",
    "plt.title('window fitting results\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_width = 50 \n",
    "window_height = 90 # Break image into 9 vertical layers since image height is 720\n",
    "margin = 30 # How much to slide left and right for searching\n",
    "\n",
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "def find_window_centroids(warped, window_width, window_height, margin):\n",
    "    \n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template \n",
    "    \n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    l_sum = np.sum(warped[int(3*warped.shape[0]/4):,:int(warped.shape[1]/2)], axis=0)\n",
    "    l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "    r_sum = np.sum(warped[int(3*warped.shape[0]/4):,int(warped.shape[1]/2):], axis=0)\n",
    "    r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(warped.shape[1]/2)\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1,(int)(warped.shape[0]/window_height)):\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        image_layer = np.sum(warped[int(warped.shape[0]-(level+1)*window_height):int(warped.shape[0]-level*window_height),:], axis=0)\n",
    "        conv_signal = np.convolve(window, image_layer)\n",
    "        # Find the best left centroid by using past left center as a reference\n",
    "        # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "        offset = window_width/4\n",
    "        l_min_index = int(max(l_center+offset-margin,0))\n",
    "        l_max_index = int(min(l_center+offset+margin,warped.shape[1]))\n",
    "        l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "        # Find the best right centroid by using past right center as a reference\n",
    "        r_min_index = int(max(r_center+offset-margin,0))\n",
    "        r_max_index = int(min(r_center+offset+margin,warped.shape[1]))\n",
    "        r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "        # Add what we found for that layer\n",
    "        window_centroids.append((l_center,r_center))\n",
    "\n",
    "    return window_centroids\n",
    "\n",
    "\n",
    "window_centroids = find_window_centroids(warped, window_width, window_height, margin)\n",
    "\n",
    "def window_centers(window_centroids):\n",
    "    # If we found any window centers\n",
    "    if len(window_centroids) > 0:\n",
    "\n",
    "        # Points used to draw all the left and right windows\n",
    "        l_points = np.zeros_like(warped)\n",
    "        r_points = np.zeros_like(warped)\n",
    "\n",
    "        # Go through each level and draw the windows \t\n",
    "        for level in range(0,len(window_centroids)):\n",
    "            # Window_mask is a function to draw window areas\n",
    "            l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "            r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "            # Add graphic points from window mask here to total pixels found \n",
    "            l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "            r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "        # Draw the results\n",
    "        template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "        zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "        template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "        warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "        return cv2.addWeighted(warpage, 1, template, 0.5, 0.0),l_points,r_points # overlay the orignal road image with window results\n",
    " \n",
    "    # If no window centers found, just display orginal road image\n",
    "    else:\n",
    "        return np.array(cv2.merge((warped,warped,warped)),np.uint8),None,None\n",
    "    \n",
    "# Display the final results\n",
    "output,l_points,r_points = window_centers(window_centroids)\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(warped,cmap=\"gray\")\n",
    "ax1.set_title('\\nWarped Image\\n', fontsize=50)\n",
    "ax2.imshow(output)\n",
    "ax2.set_title('\\nwindow fitting results\\n', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.) \n",
    "plt.savefig('./writeup_images/color_fit_lines.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust points in left and right curve\n",
    "\n",
    "        \n",
    "\n",
    "def pos_from_center(mid_point,leftbase_x,rightbase_x):\n",
    "    xm_per_pix = 3.7/700\n",
    "    offset =np.abs(mid_point - (leftbase_x+rightbase_x)/2)\n",
    "    return offset*xm_per_pix\n",
    "\n",
    "\n",
    "# def sanity_check(leftx,rightx):\n",
    "#     height = len(leftx)-1\n",
    "#     leftx_start = leftx[height]\n",
    "#     rightx_start = rightx[height]\n",
    "#     curvature_distance = 600 #np.abs(leftx_start - rightx_start)\n",
    "#     for i in range(1,len(leftx)):\n",
    "#         if(np.abs(leftx[i] - rightx[i]) < curvature_distance ):\n",
    "#               leftx[i] = rightx[i-1] - curvature_distance   \n",
    "#         if(np.abs(leftx[i] - rightx[i]) < curvature_distance ):\n",
    "#             rightx[i] = leftx[i-1]  + curvature_distance      \n",
    "#     return leftx,rightx      \n",
    "\n",
    "\n",
    "\n",
    "def get_curvature(l_points,r_points,shape):\n",
    "    \n",
    "    global previous_left_curverad\n",
    "    global previous_right_curverad\n",
    "    global previous_leftx\n",
    "    global previous_rightx\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ploty = np.linspace(0, 719, num=shape[0])\n",
    "    y_eval = np.max(ploty)\n",
    "    leftx = np.argmax(l_points, axis=1)\n",
    "    rightx = np.argmax(r_points, axis=1)\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    left_fit = np.polyfit(ploty, leftx, 2)\n",
    "    right_fit = np.polyfit(ploty, rightx, 2)\n",
    "    left_fit_x = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fit_x = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return left_curverad, right_curverad , left_fit_x,right_fit_x,left_fit_cr,right_fit_cr\n",
    "\n",
    "curvature =  get_curvature(l_points,r_points,warped.shape)\n",
    "print(curvature[0], 'm', curvature[1], 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fitted curve\n",
    "mark_size = 2\n",
    "ploty = np.linspace(0, 719, num=720)\n",
    "# plt.plot(leftx, ploty, 'o', color='red', markersize=mark_size)\n",
    "# plt.plot(rightx, ploty, 'o', color='blue', markersize=mark_size)\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(0, 720)\n",
    "plt.plot(curvature[2], ploty, color='green', linewidth=3)\n",
    "plt.plot(curvature[3], ploty, color='green', linewidth=3)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay and inverse perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_overlay(img,warped,leftx,rightx,Minv):\n",
    "    ploty = np.linspace(0, 719, num=720)\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([leftx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([rightx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), [0,255,0])\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (warped.shape[1], warped.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    return cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "\n",
    "\n",
    "result = create_overlay(test_images[test_image_index],warped,curvature[2],curvature[3],Minv)\n",
    "fig = plt.figure(figsize=(24, 14), dpi=100)\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check and smoothing detected lane lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None  \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit =[] \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = []\n",
    "        #y values for detected line pixels\n",
    "        self.ally = []\n",
    "        #x coefficients for detected line pixels\n",
    "        self.allx_coefficient = []\n",
    "        # x coefficients of the last n fits of the line\n",
    "        self.recent_x_coeffients = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx_coefficients = None \n",
    "     \n",
    "    def update_lines(self,x):\n",
    "        self.allx.append(x);\n",
    "        if(len(self.allx) < 10):\n",
    "            self.bestx = x\n",
    "            \n",
    "        \n",
    "    def update_coefficients(self,x_coefficient):\n",
    "        self.allx_coefficient.append(x_coefficient)\n",
    "        self.current_fit = x_coefficient\n",
    "        \n",
    "    def get_last_n_x_values(self,n = 10):\n",
    "        if(len(self.allx)> n):\n",
    "            self.recent_xfitted = self.allx[(len(self.allx) - n)-1:]\n",
    "    \n",
    "            \n",
    "    def get_last_n_x_coefficients(self,n = 10):\n",
    "        if(len(self.allx_coefficient)> n):\n",
    "            self.recent_x_coefficient = self.allx_coefficient[(len(self.allx_coefficient) - n)-1:]        \n",
    "            \n",
    "    def get_average_n_x_values(self,n = 10):\n",
    "        if(len(self.recent_xfitted) > n):\n",
    "            temp = self.recent_xfitted[0]\n",
    "            for i in range(1,n) :\n",
    "                temp = np.add(temp,self.recent_xfitted[i])\n",
    "            self.bestx = temp/n \n",
    "        \n",
    "    \n",
    "    def get_average_n_x_coefficients(self,n = 10):\n",
    "        if(len(self.recent_x_coeffients) > n):\n",
    "            temp = self.recent_x_coeffients[0]\n",
    "            for i in range(1,n) :\n",
    "                temp = np.add(temp,self.recent_x_coeffients[i])\n",
    "            self.bestx_coefficients = temp/n \n",
    "        \n",
    "    def set_radius_of_curvature(self,curvature):\n",
    "        self.radius_of_curvature = curvature\n",
    "        \n",
    "    def set_center_position(self,center_position):  \n",
    "        self.line_base_pos = center_position\n",
    "        \n",
    "    def get_coefficient_difference(self):  \n",
    "        diff = np.subtract(self.current_fit,self.recent_x_coefficient[len(self.recent_x_coefficient)-2])\n",
    "        diff = np.abs(diff)\n",
    "        self.diff = diff\n",
    "        \n",
    "    def remove_recent_line(self):\n",
    "        if len(self.allx) > 0:\n",
    "            self.allx = self.allx[:-1]\n",
    "            self.allx_coefficient = self.allx_coefficient[:-1]\n",
    "            \n",
    "\n",
    "def get_average_x_values(left_line,right_line,n=10):\n",
    "    left_line.remove_recent_line()\n",
    "    right_line.remove_recent_line() \n",
    "    left_line.get_last_n_x_values(10)\n",
    "    left_line.get_average_n_x_values(10)\n",
    "    right_line.get_last_n_x_values(10)\n",
    "    right_line.get_average_n_x_values(10)\n",
    "    \n",
    "    \n",
    "               \n",
    "        \n",
    "def sanitycheck(left_line,right_line):\n",
    "   \n",
    "    \n",
    "    last_index = len(left_line.allx) - 1\n",
    "    left_curvature = left_line.allx[last_index]\n",
    "    right_curvature = right_line.allx[last_index]\n",
    "    \n",
    "\n",
    "    abs_diff_1 = np.abs(np.subtract(left_line.current_fit[0],right_line.current_fit[0]))\n",
    "    abs_diff_2 = np.abs(np.subtract(left_line.current_fit[1],right_line.current_fit[1]))\n",
    "    abs_diff_3 = np.abs(np.subtract(left_line.current_fit[2],right_line.current_fit[2]))\n",
    "  \n",
    "    limit = 10.0\n",
    "    if(abs_diff_1 > limit  or abs_diff_2 > limit  or abs_diff_3 > limit ):\n",
    "        if(len(left_line.allx) > 0):\n",
    "            get_average_x_values(left_line,right_line,10)\n",
    "            left_curvature = left_line.bestx\n",
    "            right_curvature = right_line.bestx\n",
    "        return left_curvature,right_curvature\n",
    "        \n",
    "    if(np.abs(np.subtract(left_line.radius_of_curvature,right_line.radius_of_curvature)) > 2000):\n",
    "        get_average_x_values(left_line,right_line,10)\n",
    "        left_curvature = left_line.bestx\n",
    "        right_curvature = right_line.bestx\n",
    "        return left_curvature,right_curvature\n",
    "    \n",
    "    if(len(left_line.allx) > 0):\n",
    "        for i in range(0,len(left_line.allx[last_index])):\n",
    "            if(np.abs(np.subtract(left_line.allx[last_index][i],right_line.allx[last_index][i])) < 700):\n",
    "                get_average_x_values(left_line,right_line,10)\n",
    "                left_curvature = left_line.bestx\n",
    "                right_curvature = right_line.bestx\n",
    "                return left_curvature,right_curvature\n",
    "            \n",
    "    if(left_line.line_base_pos > 0.30 or right_line.line_base_pos > 0.30):\n",
    "        get_average_x_values(left_line,right_line,10)\n",
    "        left_curvature = left_line.bestx\n",
    "        right_curvature = right_line.bestx\n",
    "        return left_curvature,right_curvature\n",
    "    return left_curvature,right_curvature\n",
    "\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "\n",
    "def process_image(i):\n",
    "    #gray\n",
    "    i = np.copy(i)\n",
    "    i = cv2.undistort(i, mtx, dist, None, mtx)\n",
    "    \n",
    "#     gray = cv2.cvtColor(i, cv2.COLOR_RGB2GRAY)\n",
    "#     sobelx_gray = getSobel([gray],'x',(threshold_min,threshold_max))\n",
    "#     sobely_gray = getSobel([gray],'y',(threshold_min,threshold_max))\n",
    "#     mag_gray = mag_thresh([gray], sobel_kernel=3, mag_thresh=(threshold_min,threshold_max))\n",
    "#     dir_gray = dir_threshold([gray], sobel_kernel=15, thresh=(0.7, 1.3)) \n",
    "#     combined = get_combined(sobelx_gray,dir_gray)\n",
    "    \n",
    "\n",
    "    #s channel\n",
    "    s = get_s_channel([i])\n",
    "    sobelx_s = getSobel(s,'x',(threshold_min,threshold_max))\n",
    "    sobely_s = getSobel(s,'y',(threshold_min,threshold_max))\n",
    "    mag_s = mag_thresh(s, sobel_kernel=3, mag_thresh=(threshold_min,threshold_max))\n",
    "    dir_s = dir_threshold(s, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "    combined_s = get_combined(sobelx_s,dir_s)\n",
    "    \n",
    "    \n",
    "    #r channel\n",
    "#     r = get_r_channel([i])\n",
    "#     sobelx_r = getSobel(r,'x',(threshold_min,threshold_max))\n",
    "#     sobely_r = getSobel(r,'y',(threshold_min,threshold_max))\n",
    "#     mag_r = mag_thresh(r, sobel_kernel=3, mag_thresh=(threshold_min,threshold_max))\n",
    "#     dir_r = dir_threshold(r, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "#     combined_r = get_combined(sobelx_r,dir_r)\n",
    "    \n",
    "    #l channel\n",
    "    l = get_l_channel([i])\n",
    "    sobelx_l = getSobel(l,'x',(threshold_min,threshold_max))\n",
    "    sobely_l = getSobel(l,'y',(threshold_min,threshold_max))\n",
    "    mag_l = mag_thresh(l, sobel_kernel=3, mag_thresh=(threshold_min,threshold_max))\n",
    "    dir_l = dir_threshold(l, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "    combined_l = get_combined(sobelx_l,dir_l)\n",
    "    \n",
    "    #combine channels\n",
    "    all_combined = get_all_channels_combined(combined_s,combined_l)\n",
    "\n",
    "    ROI_all_combined = isolate_region_interest(all_combined)\n",
    "    \n",
    "    \n",
    "    warped = warp_image(ROI_all_combined[0])\n",
    "    window_centroids = find_window_centroids(warped, 50, 90, 30)\n",
    "    output,l_points,r_points = window_centers(window_centroids)\n",
    "    \n",
    "    curvature = get_curvature(l_points,r_points,warped.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    global left_line\n",
    "    global right_line\n",
    "    \n",
    "    left_line.update_lines(curvature[2])\n",
    "    right_line.update_lines(curvature[3])\n",
    "    \n",
    "    left_line.update_coefficients(curvature[4])\n",
    "    right_line.update_coefficients(curvature[5])\n",
    "    \n",
    "    \n",
    "    left_line.set_radius_of_curvature(curvature[0])\n",
    "    right_line.set_radius_of_curvature(curvature[1])\n",
    "    \n",
    "    offset = pos_from_center(i.shape[1]/2,curvature[2][i.shape[0]-1],curvature[3][i.shape[0]-1])\n",
    "    \n",
    "    left_line.set_center_position(offset)\n",
    "    right_line.set_center_position(offset)\n",
    "    \n",
    "    left_curve,right_curve = sanitycheck(left_line,right_line)\n",
    "   \n",
    "    result = create_overlay(i,warped,left_curve,right_curve,Minv)\n",
    "    \n",
    "    #Information string\n",
    "    height = result.shape[0]-1\n",
    "    curvature_string_left = \"Radius of left curve : {0:.2f} meters\".format(curvature[0])\n",
    "    curvature_string_right = \"Radius of right curve : {0:.2f} meters\".format(curvature[1])\n",
    "    location_string = \"Distance from center : {0:.2f} meters\".format(offset)\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(result,curvature_string_left,(20,50), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(result,curvature_string_right,(20,100), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(result,location_string,(20,150), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    \n",
    "    #add overlay\n",
    "    small_warped = cv2.resize(warped,(160,90))\n",
    "    y_position = 60\n",
    "    x_position = 1050\n",
    "    small_width = int(result.shape[1] * 0.125)\n",
    "    small_height = int(result.shape[0]* 0.125)\n",
    "    small_warped_copy = np.zeros_like(small_warped)\n",
    "    small_warped_copy[small_warped > 0] = 255\n",
    "    result[y_position:small_height+y_position,x_position:x_position+small_width,0 ] = small_warped_copy\n",
    "    result[y_position:small_height+y_position,x_position:x_position+small_width,1 ] = small_warped_copy\n",
    "    result[y_position:small_height+y_position,x_position:x_position+small_width,2 ] = small_warped_copy\n",
    "    cv2.putText(result,\"Top-Down view\",(x_position,40), font, 0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "    \n",
    "    small_output = cv2.resize(output,(160,90))\n",
    "    y_position = 200 \n",
    "    x_position = 1050\n",
    "    small_width = int(result.shape[1] * 0.125)\n",
    "    small_height = int(result.shape[0]* 0.125)\n",
    "    small_output_copy = np.zeros_like(small_output)\n",
    "    small_output_copy[small_output > 0] = 255\n",
    "    result[y_position:small_height+y_position,x_position:x_position+small_width] = small_output\n",
    "    \n",
    "    cv2.putText(result,\"Detected lane-lines view\",(x_position,180), font, 0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return result\n",
    "fig = plt.figure(figsize=(24, 14))\n",
    "plt.imshow(process_image(test_images[test_image_index]))\n",
    "plt.savefig('./writeup_images/example_output.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process project video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "advanced_lane_line_test_1 = 'processed_project_video.mp4'\n",
    "clip1_1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1_1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(advanced_lane_line_test_1, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(advanced_lane_line_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip(\"processed_project_video.mp4\")\n",
    "clip2=clip.resize(width=clip.w//2,height=clip.h//2).speedx(4)\n",
    "clip2.write_gif(\"processed_project_video.gif\",program= 'ffmpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
